{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "from lstmHelpers import *\n",
    "\n",
    "import random\n",
    "from random import randrange, shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "filedir = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using classes...\n",
      "Exact Classes: [3148, 4125, 7166, 4133, 4688, 4198, 2042, 7563, 301, 3992, 5054, 3025, 3654, 7551, 6591]\n",
      "Matched Classes: []\n",
      "\n",
      "\n",
      "Time elapsed: 0.024538278579711914 seconds, or 0.0004089713096618652 minutes\n"
     ]
    }
   ],
   "source": [
    "## WRITE STREAM DATA TO FILE\n",
    "start = time.time()\n",
    "total_time = time.time()\n",
    "\n",
    "NUM_CLASSES_OVERRIDE = 15  # If 0, use ALL classes; else, use n classes only\n",
    "num_files_in_stream = 50 * NUM_CLASSES_OVERRIDE\n",
    "order_to_use = []\n",
    "\n",
    "used_classes, unused_classes = load_classes(filedir, NUM_CLASSES_OVERRIDE, display=False)\n",
    "\n",
    "for i in range(NUM_CLASSES_OVERRIDE):\n",
    "    order_to_use.extend([i] * int(num_files_in_stream / NUM_CLASSES_OVERRIDE))\n",
    "    \n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"trainingInfo.txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"testingInfo.txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "\n",
    "# code you want to evaluate\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Time elapsed: 16.746337175369263 seconds, or 0.2791056195894877 minutes\n"
     ]
    }
   ],
   "source": [
    "## READ STREAM DATA FROM FILE\n",
    "\n",
    "def generate_composite_stream(audio_matrix, data_dict = None):\n",
    "    cur_percentage = 0\n",
    "    if data_dict == None:\n",
    "        data_dict = {}\n",
    "    \n",
    "    composite_signal_list = []\n",
    "    composite_matches_list = []\n",
    "    \n",
    "    for i in range(len(audio_matrix)):\n",
    "        if (round(i / len(audio_matrix) * 100) != cur_percentage):\n",
    "            cur_percentage = round(i / len(audio_matrix) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "            \n",
    "        filename = audio_matrix[i][2]\n",
    "        if filename in data_dict:\n",
    "            y = data_dict.get(filename)\n",
    "        else:\n",
    "            yt,sr = librosa.load(filename)\n",
    "            y, idx = librosa.effects.trim(yt, top_db=50)\n",
    "            data_dict[filename] = y\n",
    "        warped_y = timewarp(y, audio_matrix[i][6])\n",
    "        noisey_y = apply_noise(warped_y, audio_matrix[i][5])\n",
    "        faded_y = apply_ramp(noisey_y, audio_matrix[i][3], audio_matrix[i][4])\n",
    "        composite_signal_list.append(faded_y)\n",
    "        composite_matches_list.append(np.full(faded_y.shape, audio_matrix[i][1]))\n",
    "    composite_signal = np.array(composite_signal_list)\n",
    "    composite_signal = np.concatenate(composite_signal).ravel()\n",
    "    composite_matches = np.array(composite_matches_list)\n",
    "    composite_matches = np.concatenate(composite_matches).ravel()\n",
    "    return composite_signal, composite_matches, data_dict\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "audio_matrix = load_stream(name=\"trainingInfo.txt\")\n",
    "composite_signal, composite_matches, preloaded_data = generate_composite_stream(audio_matrix)\n",
    "audio_matrix_test = load_stream(name=\"testingInfo.txt\")\n",
    "composite_signal_test, composite_matches_test, x = generate_composite_stream(audio_matrix_test, data_dict=preloaded_data)\n",
    "\n",
    "composite_matches \n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nTime elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Testing Data\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "\n",
      "Time elapsed: 2.7932097911834717 seconds, or 0.04655349651972453 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_mels = 128\n",
    "batch_length = 10\n",
    "\n",
    "def batch(signal, matches):\n",
    "    # Generate batched data list for signal/matches\n",
    "    \n",
    "    data = []\n",
    "    classes = []\n",
    "    spec = get_spectrogram(signal, 22050, n_mels=n_mels, display=False)\n",
    "    cur_col = 0\n",
    "    transposed = spec.T\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    transposed = scaler.fit_transform(transposed)\n",
    "    cur_percentage = 0\n",
    "    for col in transposed:\n",
    "        if cur_col + batch_length >= len(transposed):\n",
    "            break\n",
    "        if (round(cur_col / len(transposed) * 100) != cur_percentage):\n",
    "            cur_percentage = round(cur_col / len(transposed) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "        comp_cols = [col]\n",
    "        for i in range(1,batch_length):\n",
    "            comp_cols.append(transposed[cur_col + i])\n",
    "        data.append(comp_cols)\n",
    "        classes.append(int(matches[int(cur_col / len(transposed) * len(matches))]))\n",
    "        cur_col += 1\n",
    "    return data, classes\n",
    "\n",
    "print(\"Training Data\")\n",
    "training_data, training_classes = batch(composite_signal, composite_matches)\n",
    "print(\"\\nTesting Data\")\n",
    "testing_data, testing_classes = batch(composite_signal_test, composite_matches_test)\n",
    "print()\n",
    "max_spec_length = len(training_data[0])\n",
    "print()\n",
    "training_data = np.array(training_data)\n",
    "testing_data = np.array(testing_data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 32 10 0.2 350 0.2 15\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 350)               670600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                5265      \n",
      "=================================================================\n",
      "Total params: 675,865\n",
      "Trainable params: 675,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "35380/35380 [==============================] - 7s 202us/step - loss: 1.0798 - acc: 0.6650\n",
      "Epoch 2/3\n",
      "35380/35380 [==============================] - 6s 172us/step - loss: 0.4930 - acc: 0.8533\n",
      "Epoch 3/3\n",
      "35380/35380 [==============================] - 6s 171us/step - loss: 0.3941 - acc: 0.8834\n",
      "35292/35292 [==============================] - 4s 123us/step\n",
      "Accuracy: 92.39%\n",
      "Total Time elapsed: 0.7316332459449768 minutes\n"
     ]
    }
   ],
   "source": [
    "# Make/test the LSTM\n",
    "\n",
    "lstm_out = 350\n",
    "batch_size = 64\n",
    "embedding_vector_length = 32\n",
    "dropout = 0.2\n",
    "dropout_r = 0.2\n",
    "\n",
    "number_inputs = NUM_CLASSES_OVERRIDE\n",
    "\n",
    "print(str(number_inputs) + \" \" + str(embedding_vector_length) + \" \" + str(len(training_data[0])) + \" \" + str(dropout) + \n",
    "      \" \" + str(lstm_out) + \" \" + str(dropout_r) + \" \" + str(NUM_CLASSES_OVERRIDE))\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_out, input_shape=(batch_length, n_mels), dropout = dropout, recurrent_dropout = dropout_r))\n",
    "model.add(Dense(NUM_CLASSES_OVERRIDE,activation='softmax'))  #softmax\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])  # sparse_categorical_crossentropy\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(training_data, training_classes, epochs=3, batch_size=batch_size)\n",
    "scores = model.evaluate(testing_data, testing_classes)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "total_end = time.time()\n",
    "print(\"Total Time elapsed: \" + str((total_end-total_time)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"LSTMModel.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesisCode]",
   "language": "python",
   "name": "conda-env-thesisCode-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
