{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "from lstmHelpers import *\n",
    "\n",
    "import random\n",
    "from random import randrange, shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from collections import deque\n",
    "import pickle\n",
    "\n",
    "\n",
    "filedir = \"lstmData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using classes...\n",
      "Exact Classes: [9207, 8719, 4693, 9533, 2412, 5581, 7873, 1249, 8011, 3957, 4213, 2836, 2143, 8238, 1587, 4296, 242, 542, 3768, 4738, 8366, 4677, 578, 2513, 4817, 3512, 3971, 8320, 8426, 4220, 5402, 2576, 9164, 855, 8881, 2651, 1087, 8983, 1339, 7978, 6122, 4703, 7968, 4651, 1895, 2149, 4566, 2686, 7297, 1622, 2933, 1401, 2902, 2292, 359, 6230, 6761, 410, 5056, 2881, 2412, 9272, 7282, 1191, 9403, 755, 2531, 8661, 4756, 4977, 2325, 3907, 59, 3586, 7289, 8111, 9688, 1338, 6974, 9348, 5947, 7797, 2934, 7397, 9324, 5810, 9058, 7493, 6727, 7920, 485, 6369, 9722, 1928, 9728, 411, 6697, 8169, 9262, 203, 3297, 5891, 2777, 8299, 8942, 656, 5285, 697, 798, 4706, 6120, 8161, 976, 7537, 1678, 2978, 9247, 4230, 7611, 2864, 3684, 1927, 166, 4807, 2189, 3103, 7646, 9863, 5441, 6072, 3016, 7107, 3525, 2652, 6619, 9567, 1240, 1792, 1483, 9298, 1165, 1617, 1436, 5023, 47, 336, 7076, 3062]\n",
      "Matched Classes: [3110, 4069, 1153, 589, 251, 2876, 88, 1813, 2954, 2759, 3745, 2842, 3874, 2226, 621, 3945, 788, 2601, 154, 1067, 3055, 2431, 2690, 4032, 994, 2899, 2263, 1551, 3764, 1716, 282, 171, 1656, 1018, 2695, 3414, 4141, 750, 3848, 119, 90, 2539, 2739, 3264, 404, 1917, 3438, 2417, 185, 686, 309, 1312]\n",
      "\n",
      "\n",
      "Time elapsed: 0.07506394386291504 seconds, or 0.001251065731048584 minutes\n"
     ]
    }
   ],
   "source": [
    "## GENERATE AND WRITE NEW STREAM DATA TO FILE\n",
    "\n",
    "start = time.time()\n",
    "total_time = time.time()\n",
    "\n",
    "NUM_QUERY_FILES = 200  # If 0, use ALL classes; else, use n classes only\n",
    "num_files_in_stream = 20 * NUM_QUERY_FILES\n",
    "order_to_use = []\n",
    "\n",
    "used_classes, unused_classes = load_classes(\"../\", NUM_QUERY_FILES, display=False)\n",
    "\n",
    "for i in range(NUM_QUERY_FILES):\n",
    "    order_to_use.extend([i] * int(num_files_in_stream / NUM_QUERY_FILES))\n",
    "    \n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"/trainingInfo_\" + str(NUM_QUERY_FILES) + \".txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"/testingInfo_\" + str(NUM_QUERY_FILES) + \".txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "\n",
    "# code you want to evaluate\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Time elapsed: 82.59444618225098 seconds, or 1.3765741030375163 minutes\n"
     ]
    }
   ],
   "source": [
    "## READ AND GENERATE STREAM DATA FROM FILE\n",
    "\n",
    "def generate_composite_stream(audio_matrix, data_dict = None):\n",
    "    cur_percentage = 0\n",
    "    if data_dict == None:\n",
    "        data_dict = {}\n",
    "    \n",
    "    composite_signal_list = []\n",
    "    composite_matches_list = []\n",
    "    \n",
    "    for i in range(len(audio_matrix)):\n",
    "        if (round(i / len(audio_matrix) * 100) != cur_percentage):\n",
    "            cur_percentage = round(i / len(audio_matrix) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "            \n",
    "        filename = audio_matrix[i][0]\n",
    "        if filename in data_dict:\n",
    "            y = data_dict.get(filename)\n",
    "        else:\n",
    "            yt,sr = librosa.load(filename)\n",
    "            y, idx = librosa.effects.trim(yt, top_db=50)\n",
    "            data_dict[filename] = y\n",
    "        warped_y = timewarp(y, audio_matrix[i][6])\n",
    "        noisey_y = apply_noise(warped_y, audio_matrix[i][5])\n",
    "        faded_y = apply_ramp(noisey_y, audio_matrix[i][3], audio_matrix[i][4])\n",
    "        composite_signal_list.append(faded_y)\n",
    "        composite_matches_list.append(np.full(faded_y.shape, audio_matrix[i][1]))\n",
    "    composite_signal = np.array(composite_signal_list)\n",
    "    composite_signal = np.concatenate(composite_signal).ravel()\n",
    "    composite_matches = np.array(composite_matches_list)\n",
    "    composite_matches = np.concatenate(composite_matches).ravel()\n",
    "    return composite_signal, composite_matches, data_dict\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "audio_matrix = load_stream(name=\"/trainingInfo_\" + str(NUM_QUERY_FILES) + \".txt\", filedir=filedir)\n",
    "composite_signal, composite_matches, preloaded_data = generate_composite_stream(audio_matrix)\n",
    "#audio_matrix_test = load_stream(name=\"/testingInfo_\" + str(NUM_QUERY_FILES) + \".txt\", filedir=filedir)\n",
    "#composite_signal_test, composite_matches_test, x = generate_composite_stream(audio_matrix_test, data_dict=preloaded_data)\n",
    "\n",
    "audio_matrix = []\n",
    "audio_matrix_test = []\n",
    "preloaded_data = {}\n",
    "\n",
    "NUM_CLASSES_USED = len(set(composite_matches))\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nTime elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 350)               670600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               70200     \n",
      "=================================================================\n",
      "Total params: 740,800\n",
      "Trainable params: 740,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training Data: 0 / 105161216 ~= 0%\n",
      "Training Data: 256000 / 105161216 ~= 0%\n",
      "Training Data: 512000 / 105161216 ~= 0%\n",
      "Training Data: 768000 / 105161216 ~= 1%\n",
      "Training Data: 1024000 / 105161216 ~= 1%\n",
      "Training Data: 1280000 / 105161216 ~= 1%\n",
      "Training Data: 1536000 / 105161216 ~= 1%\n"
     ]
    }
   ],
   "source": [
    "## MINI-BATCH TESTING CELL\n",
    "\n",
    "def batch(signal, matches, hop_length = 512/8, print_output=False):\n",
    "    signal_batch_length = 2048*3\n",
    "    data = []\n",
    "    classes = []\n",
    "    \n",
    "    batched_frames = []\n",
    "    cur_frame_count = 0\n",
    "    cur_percentage = 0\n",
    "    num_to_add  = signal_batch_length\n",
    "    while cur_frame_count < len(signal):\n",
    "        batched_frames.extend(signal[cur_frame_count : cur_frame_count + num_to_add - 1])\n",
    "        recent_signal = np.asarray(batched_frames)\n",
    "        recent_signal = np.pad(recent_signal, (0, 2048), 'constant', constant_values=(0.0,0.0))\n",
    "        spec = get_spectrogram(recent_signal, 22050, n_mels=n_mels, display=False)\n",
    "        transposed = spec.T\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        transposed = scaler.fit_transform(transposed)\n",
    "        comp_cols = []\n",
    "        for i in range(0,seq_length):\n",
    "            comp_cols.append(transposed[i])\n",
    "        data.append(comp_cols)\n",
    "        classes.append(int(matches[cur_frame_count-1]))\n",
    "        batched_frames = batched_frames[int(hop_length)-1:]  # hop length of spectrogram / 8\n",
    "        \n",
    "        if print_output and round((cur_frame_count-1) / len(signal) * 100) != cur_percentage:\n",
    "            cur_percentage = round((cur_frame_count-1) / len(signal) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "            \n",
    "        cur_frame_count += num_to_add\n",
    "        num_to_add = int(hop_length)\n",
    "        \n",
    "    return data, classes\n",
    "\n",
    "start = time.time()\n",
    "n_mels = 128\n",
    "seq_length = 10\n",
    "\n",
    "start_point = 0\n",
    "batch_length = 5000  # In # of sequences\n",
    "audio_window= 64\n",
    "batch_window = batch_length * audio_window\n",
    "\n",
    "lstm_out = 350\n",
    "batch_size = 32\n",
    "dropout = 0.1\n",
    "dropout_r = 0.1\n",
    "number_outputs = NUM_CLASSES_USED\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_out, input_shape=(seq_length, n_mels), dropout = dropout, recurrent_dropout = dropout_r))\n",
    "model.add(Dense(number_outputs,activation='softmax'))  #softmax\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])  # sparse_categorical_crossentropy\n",
    "print(model.summary())\n",
    "\n",
    "composite_signal_length = len(composite_signal)\n",
    "\n",
    "acc_0 = []\n",
    "acc_1 = []\n",
    "acc_2 = []\n",
    "acc_3 = []\n",
    "\n",
    "while start_point + batch_window < composite_signal_length:\n",
    "    print(\"Training Data: \" + str(start_point) + \" / \" + str(composite_signal_length) + \" ~= \" + str(round(start_point / composite_signal_length * 100)) + \"%\")\n",
    "    training_data, training_classes = batch(composite_signal[start_point:start_point+batch_window], composite_matches[start_point:start_point+batch_window])\n",
    "    training_data = np.array(training_data)\n",
    "    history = model.fit(training_data, training_classes, epochs=4, batch_size=batch_size, verbose=0, shuffle=True)\n",
    "    accuracies = history.history['acc']\n",
    "    acc_0.append(accuracies[0])\n",
    "    acc_1.append(accuracies[1])\n",
    "    acc_2.append(accuracies[2])\n",
    "    acc_3.append(accuracies[3])\n",
    "    os.write(1, str(str(round(start_point / composite_signal_length * 100)) + \"\\n\").encode())\n",
    "    start_point += batch_window\n",
    "    \n",
    "os.write(1,\"Completed Training\\n\".encode())\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as mp\n",
    "\n",
    "plt.figure(figsize = (15,11))\n",
    "plt.plot( np.arange(len(acc_0)), acc_0, label='Epoch 1')\n",
    "plt.plot( np.arange(len(acc_1)), acc_1, label='Epoch 2')\n",
    "plt.plot( np.arange(len(acc_2)), acc_2, label='Epoch 3')\n",
    "plt.plot( np.arange(len(acc_3)), acc_3, label='Epoch 4')\n",
    "plt.legend()\n",
    "\n",
    "mp.savefig(filedir + '/accuracies_' + str(NUM_QUERY_FILES) + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(filedir + \"/LSTMModel_\" + str(NUM_QUERY_FILES) + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING NETWORK\n",
    "\n",
    "print(\"\\nTesting Data\")\n",
    "testing_data, testing_classes = batch(composite_signal_test, composite_matches_test)\n",
    "testing_data = np.array(testing_data)\n",
    "\n",
    "scores = model.evaluate(testing_data, testing_classes)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesisCode]",
   "language": "python",
   "name": "conda-env-thesisCode-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
