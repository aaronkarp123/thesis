{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "from lstmHelpers import *\n",
    "\n",
    "import random\n",
    "from random import randrange, shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "filedir = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using classes...\n",
      "Exact Classes: [4576, 9842, 9476, 1699, 7403, 10024, 6841, 3749, 10100, 294, 2482, 2955, 4013, 2176, 5262, 7764, 7061, 2440, 3078, 84, 4157, 7222, 7510, 2903, 7113, 6297, 9749, 5742, 3728, 977, 1254, 7833, 7563, 3295, 7610, 9901, 573, 2054, 6317, 7619, 7172, 6818, 8297, 9232, 8843, 4397, 9875, 5733, 1450, 1297, 9121, 2761, 816, 7575, 7002, 8751, 6529, 8400]\n",
      "Matched Classes: [3337, 2834, 362, 1845, 325, 3061, 221, 1161, 3975, 2147, 3493, 3026, 932, 98, 1167, 3346, 1835, 760, 2722, 1409, 2682, 1816]\n",
      "\n",
      "\n",
      "Time elapsed: 0.028449296951293945 seconds, or 0.0004741549491882324 minutes\n"
     ]
    }
   ],
   "source": [
    "## WRITE STREAM DATA TO FILE\n",
    "start = time.time()\n",
    "total_time = time.time()\n",
    "\n",
    "NUM_CLASSES_OVERRIDE = 40  # If 0, use ALL classes; else, use n classes only\n",
    "num_files_in_stream = 30 * NUM_CLASSES_OVERRIDE\n",
    "order_to_use = []\n",
    "\n",
    "used_classes, unused_classes = load_classes(filedir, NUM_CLASSES_OVERRIDE, display=False)\n",
    "\n",
    "for i in range(NUM_CLASSES_OVERRIDE):\n",
    "    order_to_use.extend([i] * int(num_files_in_stream / NUM_CLASSES_OVERRIDE))\n",
    "    \n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"trainingInfo.txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"testingInfo.txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "\n",
    "# code you want to evaluate\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blank Segment at File Start\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Blank Segment at File Start\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Time elapsed: 8.663949966430664 seconds, or 0.14439916610717773 minutes\n"
     ]
    }
   ],
   "source": [
    "## READ STREAM DATA FROM FILE\n",
    "\n",
    "def load_stream(name, filedir='../'):\n",
    "    training_file = open(filedir + name, \"r\")\n",
    "    info = training_file.read().split('\\n')\n",
    "    data_matrix = []\n",
    "    for inf in info:\n",
    "        segs = inf.split('-_-')\n",
    "        if len(segs) > 1:\n",
    "            try:\n",
    "                data_matrix.append([segs[0].strip(), segs[1].strip(), segs[2].strip(), segs[3].strip(), segs[4].strip()])\n",
    "            except Exception as e:\n",
    "                #print(e)\n",
    "                print(inf)\n",
    "        else:\n",
    "            print(\"\\nBlank Segment at File Start\")\n",
    "    training_file.close()\n",
    "    return data_matrix\n",
    "\n",
    "def generate_composite_stream(audio_matrix, data_dict = None):\n",
    "    cur_percentage = 0\n",
    "    if data_dict == None:\n",
    "        data_dict = {}\n",
    "    \n",
    "    composite_signal_list = []\n",
    "    composite_matches_list = []\n",
    "    \n",
    "    for i in range(len(audio_matrix)):\n",
    "        if (round(i / len(audio_matrix) * 100) != cur_percentage):\n",
    "            cur_percentage = round(i / len(audio_matrix) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "            \n",
    "        filename = audio_matrix[i][2]\n",
    "        if filename in data_dict:\n",
    "            y = data_dict.get(filename)\n",
    "        else:\n",
    "            yt,sr = librosa.load(filename)\n",
    "            y, idx = librosa.effects.trim(yt, top_db=50)\n",
    "            data_dict[filename] = y\n",
    "        faded_y = apply_ramp(y, audio_matrix[i][3], audio_matrix[i][4])\n",
    "        composite_signal_list.append(faded_y)\n",
    "        composite_matches_list.append(np.full(faded_y.shape, audio_matrix[i][1]))\n",
    "    composite_signal = np.array(composite_signal_list)\n",
    "    composite_signal = np.concatenate(composite_signal).ravel()\n",
    "    composite_matches = np.array(composite_matches_list)\n",
    "    composite_matches = np.concatenate(composite_matches).ravel()\n",
    "    return composite_signal, composite_matches, data_dict\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "audio_matrix = load_stream(name=\"trainingInfo.txt\")\n",
    "composite_signal, composite_matches, preloaded_data = generate_composite_stream(audio_matrix)\n",
    "audio_matrix_test = load_stream(name=\"testingInfo.txt\")\n",
    "composite_signal_test, composite_matches_test, x = generate_composite_stream(audio_matrix_test, data_dict=preloaded_data)\n",
    "\n",
    "composite_matches \n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nTime elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Testing Data\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "\n",
      "Time elapsed: 11.483063459396362 seconds, or 0.19138439098993937 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_mels = 128\n",
    "batch_length = 20\n",
    "\n",
    "def batch(signal, matches):\n",
    "    # Generate batched data list for signal/matches\n",
    "    \n",
    "    data = []\n",
    "    classes = []\n",
    "    spec = get_spectrogram(signal, 22050, n_mels=n_mels, display=False)\n",
    "    cur_col = 0\n",
    "    transposed = spec.T\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    transposed = scaler.fit_transform(transposed)\n",
    "    cur_percentage = 0\n",
    "    for col in transposed:\n",
    "        if cur_col + batch_length >= len(transposed):\n",
    "            break\n",
    "        if (round(cur_col / len(transposed) * 100) != cur_percentage):\n",
    "            cur_percentage = round(cur_col / len(transposed) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "        comp_cols = [col]\n",
    "        for i in range(1,batch_length):\n",
    "            comp_cols.append(transposed[cur_col + i])\n",
    "        data.append(comp_cols)\n",
    "        classes.append(int(matches[int(cur_col / len(transposed) * len(matches))]))\n",
    "        cur_col += 1\n",
    "    return data, classes\n",
    "\n",
    "print(\"Training Data\")\n",
    "training_data, training_classes = batch(composite_signal, composite_matches)\n",
    "print(\"\\nTesting Data\")\n",
    "testing_data, testing_classes = batch(composite_signal_test, composite_matches_test)\n",
    "print()\n",
    "max_spec_length = len(training_data[0])\n",
    "print()\n",
    "training_data = np.array(training_data)\n",
    "testing_data = np.array(testing_data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 32 20 0.2 250 0.2 80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 250)               379000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 80)                20080     \n",
      "=================================================================\n",
      "Total params: 399,080\n",
      "Trainable params: 399,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "125175/125175 [==============================] - 35s 282us/step - loss: 1.6177 - acc: 0.5853\n",
      "Epoch 2/3\n",
      "125175/125175 [==============================] - 35s 279us/step - loss: 0.5540 - acc: 0.8611\n",
      "Epoch 3/3\n",
      "125175/125175 [==============================] - 35s 280us/step - loss: 0.3936 - acc: 0.9013\n",
      "125175/125175 [==============================] - 26s 208us/step\n",
      "Accuracy: 93.31%\n",
      "Total Time elapsed: 6.157628858089447 minutes\n"
     ]
    }
   ],
   "source": [
    "# Make/test the LSTM\n",
    "\n",
    "lstm_out = 250\n",
    "batch_size = 64\n",
    "embedding_vector_length = 32\n",
    "dropout = 0.2\n",
    "dropout_r = 0.2\n",
    "\n",
    "number_inputs = NUM_CLASSES_OVERRIDE\n",
    "\n",
    "print(str(number_inputs) + \" \" + str(embedding_vector_length) + \" \" + str(len(training_data[0])) + \" \" + str(dropout) + \n",
    "      \" \" + str(lstm_out) + \" \" + str(dropout_r) + \" \" + str(NUM_CLASSES_OVERRIDE))\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_out, input_shape=(batch_length, n_mels), dropout = dropout, recurrent_dropout = dropout_r))\n",
    "model.add(Dense(NUM_CLASSES_OVERRIDE,activation='softmax'))  #softmax\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])  # sparse_categorical_crossentropy\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(training_data, training_classes, epochs=3, batch_size=batch_size)\n",
    "scores = model.evaluate(testing_data, testing_classes)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "total_end = time.time()\n",
    "print(\"Total Time elapsed: \" + str((total_end-total_time)/60.0) + \" minutes\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesisCode]",
   "language": "python",
   "name": "conda-env-thesisCode-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
