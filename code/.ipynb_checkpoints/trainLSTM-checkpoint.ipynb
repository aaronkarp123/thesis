{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "from lstmHelpers import *\n",
    "\n",
    "import random\n",
    "from random import randrange, shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from collections import deque\n",
    "import pickle\n",
    "\n",
    "\n",
    "filedir = \"lstmData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using classes...\n",
      "Exact Classes: [9423, 8232, 8988, 2376, 9137, 5671, 6858, 5638, 1638, 8470, 2360, 3621, 1731, 3441, 7895, 2894, 7878, 7165, 6504, 6440, 244, 4645, 10127, 8929, 9572, 6287, 1647, 9152, 1548, 3493, 6615, 2749, 9113, 1087, 1656, 2107, 7284, 691, 7082, 3783, 8751, 1985, 3677, 4848, 2360, 10004, 748, 7868, 5960, 7104, 2110, 1487, 1888, 994, 4310, 9078, 1344, 2919, 200, 3809, 8111, 7437, 22, 1876, 118, 7431, 9522, 8888, 9343, 4800, 358, 2800, 1887, 5263, 7459, 4699, 8652, 5011, 10034, 6477, 1821, 4593, 9603, 2638, 6136, 3140, 2673, 4342, 10114, 702, 3607, 8382, 3674, 4454, 9416, 8297, 8520, 6932, 5027, 946, 3362, 6298, 8736, 3756, 1953, 9359, 3607, 8993, 307, 6513, 2801, 6388, 2777, 9907, 344, 826, 4303, 8608, 9829, 4040, 477, 1345, 5365, 4999, 2734, 5236, 8158, 3912, 838, 7588, 7115, 4123, 3972, 8228, 1415, 1270, 10198, 2397, 9019, 8318, 1150, 4427, 6243, 6140, 4013, 3280, 219, 4136, 2902, 9801, 1395]\n",
      "Matched Classes: [4171, 1120, 1781, 4099, 15, 1734, 3465, 0, 3522, 1359, 4017, 859, 3383, 812, 4189, 1326, 3160, 1151, 2585, 3866, 3998, 1573, 3274, 1336, 2914, 712, 586, 2552, 3578, 2773, 1229, 1871, 2643, 2776, 3796, 749, 3988, 1960, 3765, 2762, 3085, 2340, 3949, 785, 1857, 2496, 3670, 982, 868]\n",
      "\n",
      "\n",
      "Time elapsed: 0.17065834999084473 seconds, or 0.0028443058331807454 minutes\n"
     ]
    }
   ],
   "source": [
    "## GENERATE AND WRITE NEW STREAM DATA TO FILE\n",
    "\n",
    "start = time.time()\n",
    "total_time = time.time()\n",
    "\n",
    "NUM_QUERY_FILES = 200  # If 0, use ALL classes; else, use n classes only\n",
    "num_files_in_stream = 20 * NUM_QUERY_FILES\n",
    "order_to_use = []\n",
    "\n",
    "used_classes, unused_classes = load_classes(\"../\", NUM_QUERY_FILES, display=False)\n",
    "\n",
    "for i in range(NUM_QUERY_FILES):\n",
    "    order_to_use.extend([i] * int(num_files_in_stream / NUM_QUERY_FILES))\n",
    "    \n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"/trainingInfo_\" + str(NUM_QUERY_FILES) + \".txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"/testingInfo_\" + str(NUM_QUERY_FILES) + \".txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "\n",
    "# code you want to evaluate\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Time elapsed: 130.53299021720886 seconds, or 2.175549836953481 minutes\n"
     ]
    }
   ],
   "source": [
    "## READ AND GENERATE STREAM DATA FROM FILE\n",
    "\n",
    "def generate_composite_stream(audio_matrix, data_dict = None):\n",
    "    cur_percentage = 0\n",
    "    if data_dict == None:\n",
    "        data_dict = {}\n",
    "    \n",
    "    composite_signal_list = []\n",
    "    composite_matches_list = []\n",
    "    \n",
    "    for i in range(len(audio_matrix)):\n",
    "        if (round(i / len(audio_matrix) * 100) != cur_percentage):\n",
    "            cur_percentage = round(i / len(audio_matrix) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "            \n",
    "        filename = audio_matrix[i][0]\n",
    "        if filename in data_dict:\n",
    "            y = data_dict.get(filename)\n",
    "        else:\n",
    "            yt,sr = librosa.load(filename)\n",
    "            y, idx = librosa.effects.trim(yt, top_db=50)\n",
    "            data_dict[filename] = y\n",
    "        warped_y = timewarp(y, audio_matrix[i][6])\n",
    "        noisey_y = apply_noise(warped_y, audio_matrix[i][5])\n",
    "        faded_y = apply_ramp(noisey_y, audio_matrix[i][3], audio_matrix[i][4])\n",
    "        composite_signal_list.append(faded_y)\n",
    "        composite_matches_list.append(np.full(faded_y.shape, audio_matrix[i][1]))\n",
    "    composite_signal = np.array(composite_signal_list)\n",
    "    composite_signal = np.concatenate(composite_signal).ravel()\n",
    "    composite_matches = np.array(composite_matches_list)\n",
    "    composite_matches = np.concatenate(composite_matches).ravel()\n",
    "    return composite_signal, composite_matches, data_dict\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "audio_matrix = load_stream(name=\"/trainingInfo_\" + str(NUM_QUERY_FILES) + \".txt\", filedir=filedir)\n",
    "composite_signal, composite_matches, preloaded_data = generate_composite_stream(audio_matrix)\n",
    "#audio_matrix_test = load_stream(name=\"/testingInfo_\" + str(NUM_QUERY_FILES) + \".txt\", filedir=filedir)\n",
    "#composite_signal_test, composite_matches_test, x = generate_composite_stream(audio_matrix_test, data_dict=preloaded_data)\n",
    "\n",
    "audio_matrix = []\n",
    "audio_matrix_test = []\n",
    "preloaded_data = {}\n",
    "\n",
    "NUM_CLASSES_USED = len(set(composite_matches))\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nTime elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 350)               670600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               70200     \n",
      "=================================================================\n",
      "Total params: 740,800\n",
      "Trainable params: 740,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training Data: 0 / 182115840 ~= 0%\n",
      "Training Data: 256000 / 182115840 ~= 0%\n",
      "Training Data: 512000 / 182115840 ~= 0%\n",
      "Training Data: 768000 / 182115840 ~= 0%\n",
      "Training Data: 1024000 / 182115840 ~= 1%\n",
      "Training Data: 1280000 / 182115840 ~= 1%\n"
     ]
    }
   ],
   "source": [
    "## MINI-BATCH TESTING CELL\n",
    "\n",
    "def batch(signal, matches, hop_length = 512/8, print_output=False):\n",
    "    signal_batch_length = 2048*3\n",
    "    data = []\n",
    "    classes = []\n",
    "    \n",
    "    batched_frames = []\n",
    "    cur_frame_count = 0\n",
    "    cur_percentage = 0\n",
    "    num_to_add  = signal_batch_length\n",
    "    while cur_frame_count < len(signal):\n",
    "        batched_frames.extend(signal[cur_frame_count : cur_frame_count + num_to_add - 1])\n",
    "        recent_signal = np.asarray(batched_frames)\n",
    "        recent_signal = np.pad(recent_signal, (0, 2048), 'constant', constant_values=(0.0,0.0))\n",
    "        spec = get_spectrogram(recent_signal, 22050, n_mels=n_mels, display=False)\n",
    "        cur_col = 0\n",
    "        transposed = spec.T\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        transposed = scaler.fit_transform(transposed)\n",
    "        comp_cols = []\n",
    "        for i in range(0,seq_length):\n",
    "            comp_cols.append(transposed[cur_col + i])\n",
    "        data.append(comp_cols)\n",
    "        classes.append(int(matches[cur_frame_count-1]))\n",
    "        batched_frames = batched_frames[int(hop_length)-1:]  # hop length of spectrogram / 8\n",
    "        \n",
    "        if print_output and round((cur_frame_count-1) / len(signal) * 100) != cur_percentage:\n",
    "            cur_percentage = round((cur_frame_count-1) / len(signal) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "            \n",
    "        cur_frame_count += num_to_add\n",
    "        num_to_add = int(hop_length)\n",
    "        \n",
    "    return data, classes\n",
    "\n",
    "start = time.time()\n",
    "n_mels = 128\n",
    "seq_length = 10\n",
    "\n",
    "start_point = 0\n",
    "batch_length = 4000  # In # of sequences\n",
    "audio_window= 64\n",
    "batch_window = batch_length * audio_window\n",
    "\n",
    "lstm_out = 350\n",
    "batch_size = 32\n",
    "embedding_vector_length = 32\n",
    "dropout = 0.1\n",
    "dropout_r = 0.1\n",
    "number_inputs = NUM_CLASSES_USED\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_out, input_shape=(seq_length, n_mels), dropout = dropout, recurrent_dropout = dropout_r))\n",
    "model.add(Dense(NUM_CLASSES_USED,activation='softmax'))  #softmax\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])  # sparse_categorical_crossentropy\n",
    "print(model.summary())\n",
    "\n",
    "composite_signal_length = len(composite_signal)\n",
    "\n",
    "acc_0 = []\n",
    "acc_1 = []\n",
    "acc_2 = []\n",
    "acc_3 = []\n",
    "\n",
    "while start_point + batch_window < composite_signal_length:\n",
    "    print(\"Training Data: \" + str(start_point) + \" / \" + str(composite_signal_length) + \" ~= \" + str(round(start_point / composite_signal_length * 100)) + \"%\")\n",
    "    training_data, training_classes = batch(composite_signal[start_point:start_point+batch_window], composite_matches[start_point:start_point+batch_window])\n",
    "    training_data = np.array(training_data)\n",
    "    history = model.fit(training_data, training_classes, epochs=4, batch_size=batch_size, verbose=0, shuffle=True)\n",
    "    accuracies = history.history['acc']\n",
    "    acc_0.append(accuracies[0])\n",
    "    acc_1.append(accuracies[1])\n",
    "    acc_2.append(accuracies[2])\n",
    "    acc_3.append(accuracies[3])\n",
    "    os.write(1, str(str(round(start_point / composite_signal_length * 100)) + \"\\n\").encode())\n",
    "    start_point += batch_window\n",
    "    \n",
    "os.write(1,\"Completed Training\\n\".encode())\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as mp\n",
    "\n",
    "plt.figure(figsize = (15,11))\n",
    "plt.plot( np.arange(len(acc_0)), acc_0, label='Epoch 1')\n",
    "plt.plot( np.arange(len(acc_1)), acc_1, label='Epoch 2')\n",
    "plt.plot( np.arange(len(acc_2)), acc_2, label='Epoch 3')\n",
    "plt.plot( np.arange(len(acc_3)), acc_3, label='Epoch 4')\n",
    "plt.legend()\n",
    "\n",
    "mp.savefig(filedir + '/accuracies_' + str(NUM_QUERY_FILES) + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(filedir + \"/LSTMModel_\" + str(NUM_QUERY_FILES) + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING NETWORK\n",
    "\n",
    "print(\"\\nTesting Data\")\n",
    "testing_data, testing_classes = batch(composite_signal_test, composite_matches_test)\n",
    "testing_data = np.array(testing_data)\n",
    "\n",
    "scores = model.evaluate(testing_data, testing_classes)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesisCode]",
   "language": "python",
   "name": "conda-env-thesisCode-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
