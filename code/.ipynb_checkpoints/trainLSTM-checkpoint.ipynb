{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helpers import *\n",
    "from lstmHelpers import *\n",
    "\n",
    "import random\n",
    "from random import randrange, shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "filedir = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using classes...\n",
      "Exact Classes: [3226, 6305, 1820, 5896, 5641, 3815, 6348, 2244, 2999, 10152, 6943, 4837, 5371, 2089, 5225, 4072, 7941, 3049, 9643, 3057, 6499, 5892, 9194, 234, 2933, 4113, 1109, 6758, 858, 778, 2482, 8496, 9667, 2745, 7009, 3956, 4754, 4446, 4572, 2664, 3994, 7857, 4989, 5150, 3980, 7960, 8400, 4974, 5504, 4698, 5504, 6559, 1584, 9207, 9789, 9373, 6247, 8909, 375, 9510, 793, 2027, 2895, 8996, 3273, 9456, 5527, 9715, 975, 9751, 5351, 6753, 7468, 7976, 7573, 4759, 9271, 5627, 9985, 2383, 2463, 2089, 8392, 8573, 7843, 9495, 3668, 5223, 9812, 9581, 111, 5407, 6474, 1732, 8627, 9924, 5775, 5823, 6441, 1788, 8503, 10121, 5728, 2518, 3836, 3680, 9781, 2507, 4285, 323]\n",
      "Matched Classes: [624, 940, 3698, 523, 185, 3935, 3357, 1483, 1069, 144, 433, 1499, 1404, 102, 1987, 3500, 1442, 2682, 560, 2362, 2308, 293, 2101, 2202, 84, 3384, 2884, 1676, 104, 1542, 1335, 3440, 3082, 3454, 1951, 2256, 1034, 2942, 3773, 2402]\n",
      "\n",
      "\n",
      "Time elapsed: 0.04066896438598633 seconds, or 0.0006778160730997721 minutes\n"
     ]
    }
   ],
   "source": [
    "## WRITE STREAM DATA TO FILE\n",
    "start = time.time()\n",
    "total_time = time.time()\n",
    "\n",
    "NUM_CLASSES_OVERRIDE = 150  # If 0, use ALL classes; else, use n classes only\n",
    "num_files_in_stream = 30 * NUM_CLASSES_OVERRIDE\n",
    "order_to_use = []\n",
    "\n",
    "used_classes, unused_classes = load_classes(filedir, NUM_CLASSES_OVERRIDE, display=False)\n",
    "\n",
    "for i in range(NUM_CLASSES_OVERRIDE):\n",
    "    order_to_use.extend([i] * int(num_files_in_stream / NUM_CLASSES_OVERRIDE))\n",
    "    \n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"trainingInfo.txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "shuffle(order_to_use)\n",
    "generate_data_file(\"testingInfo.txt\", filedir, used_classes, unused_classes, order_to_use, max_ramp_length=0.25)\n",
    "\n",
    "# code you want to evaluate\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blank Segment at File Start\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Blank Segment at File Start\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Time elapsed: 16.501006841659546 seconds, or 0.2750167806943258 minutes\n"
     ]
    }
   ],
   "source": [
    "## READ STREAM DATA FROM FILE\n",
    "\n",
    "def generate_composite_stream(audio_matrix, data_dict = None):\n",
    "    cur_percentage = 0\n",
    "    if data_dict == None:\n",
    "        data_dict = {}\n",
    "    \n",
    "    composite_signal_list = []\n",
    "    composite_matches_list = []\n",
    "    \n",
    "    for i in range(len(audio_matrix)):\n",
    "        if (round(i / len(audio_matrix) * 100) != cur_percentage):\n",
    "            cur_percentage = round(i / len(audio_matrix) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "            \n",
    "        filename = audio_matrix[i][2]\n",
    "        if filename in data_dict:\n",
    "            y = data_dict.get(filename)\n",
    "        else:\n",
    "            yt,sr = librosa.load(filename)\n",
    "            y, idx = librosa.effects.trim(yt, top_db=50)\n",
    "            data_dict[filename] = y\n",
    "        faded_y = apply_ramp(y, audio_matrix[i][3], audio_matrix[i][4])\n",
    "        composite_signal_list.append(faded_y)\n",
    "        composite_matches_list.append(np.full(faded_y.shape, audio_matrix[i][1]))\n",
    "    composite_signal = np.array(composite_signal_list)\n",
    "    composite_signal = np.concatenate(composite_signal).ravel()\n",
    "    composite_matches = np.array(composite_matches_list)\n",
    "    composite_matches = np.concatenate(composite_matches).ravel()\n",
    "    return composite_signal, composite_matches, data_dict\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "audio_matrix = load_stream(name=\"trainingInfo.txt\")\n",
    "composite_signal, composite_matches, preloaded_data = generate_composite_stream(audio_matrix)\n",
    "audio_matrix_test = load_stream(name=\"testingInfo.txt\")\n",
    "composite_signal_test, composite_matches_test, x = generate_composite_stream(audio_matrix_test, data_dict=preloaded_data)\n",
    "\n",
    "composite_matches \n",
    "\n",
    "end = time.time()\n",
    "print(\"\\nTime elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "Testing Data\n",
      "1%     2%     3%     4%     5%     6%     7%     8%     9%     10%     11%     12%     13%     14%     15%     16%     17%     18%     19%     20%     21%     22%     23%     24%     25%     26%     27%     28%     29%     30%     31%     32%     33%     34%     35%     36%     37%     38%     39%     40%     41%     42%     43%     44%     45%     46%     47%     48%     49%     50%     51%     52%     53%     54%     55%     56%     57%     58%     59%     60%     61%     62%     63%     64%     65%     66%     67%     68%     69%     70%     71%     72%     73%     74%     75%     76%     77%     78%     79%     80%     81%     82%     83%     84%     85%     86%     87%     88%     89%     90%     91%     92%     93%     94%     95%     96%     97%     98%     99%     100%     \n",
      "\n",
      "Time elapsed: 20.329976797103882 seconds, or 0.338832946618398 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_mels = 128\n",
    "batch_length = 20\n",
    "\n",
    "def batch(signal, matches):\n",
    "    # Generate batched data list for signal/matches\n",
    "    \n",
    "    data = []\n",
    "    classes = []\n",
    "    spec = get_spectrogram(signal, 22050, n_mels=n_mels, display=False)\n",
    "    cur_col = 0\n",
    "    transposed = spec.T\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    transposed = scaler.fit_transform(transposed)\n",
    "    cur_percentage = 0\n",
    "    for col in transposed:\n",
    "        if cur_col + batch_length >= len(transposed):\n",
    "            break\n",
    "        if (round(cur_col / len(transposed) * 100) != cur_percentage):\n",
    "            cur_percentage = round(cur_col / len(transposed) * 100)\n",
    "            print(str(cur_percentage) + \"%     \", end='')\n",
    "        comp_cols = [col]\n",
    "        for i in range(1,batch_length):\n",
    "            comp_cols.append(transposed[cur_col + i])\n",
    "        data.append(comp_cols)\n",
    "        classes.append(int(matches[int(cur_col / len(transposed) * len(matches))]))\n",
    "        cur_col += 1\n",
    "    return data, classes\n",
    "\n",
    "print(\"Training Data\")\n",
    "training_data, training_classes = batch(composite_signal, composite_matches)\n",
    "print(\"\\nTesting Data\")\n",
    "testing_data, testing_classes = batch(composite_signal_test, composite_matches_test)\n",
    "print()\n",
    "max_spec_length = len(training_data[0])\n",
    "print()\n",
    "training_data = np.array(training_data)\n",
    "testing_data = np.array(testing_data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \" + str(end-start) + \" seconds, or \" + str((end-start)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 32 20 0.2 350 0.2 150\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 350)               670600    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 150)               52650     \n",
      "=================================================================\n",
      "Total params: 723,250\n",
      "Trainable params: 723,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "223950/223950 [==============================] - 69s 307us/step - loss: 1.6692 - acc: 0.5977\n",
      "Epoch 2/3\n",
      "223950/223950 [==============================] - 68s 305us/step - loss: 0.5936 - acc: 0.8498\n",
      "Epoch 3/3\n",
      "223950/223950 [==============================] - 68s 305us/step - loss: 0.4328 - acc: 0.8877\n",
      "223950/223950 [==============================] - 51s 226us/step\n",
      "Accuracy: 91.77%\n",
      "Total Time elapsed: 13.576078740755717 minutes\n"
     ]
    }
   ],
   "source": [
    "# Make/test the LSTM\n",
    "\n",
    "lstm_out = 350\n",
    "batch_size = 64\n",
    "embedding_vector_length = 32\n",
    "dropout = 0.2\n",
    "dropout_r = 0.2\n",
    "\n",
    "number_inputs = NUM_CLASSES_OVERRIDE\n",
    "\n",
    "print(str(number_inputs) + \" \" + str(embedding_vector_length) + \" \" + str(len(training_data[0])) + \" \" + str(dropout) + \n",
    "      \" \" + str(lstm_out) + \" \" + str(dropout_r) + \" \" + str(NUM_CLASSES_OVERRIDE))\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_out, input_shape=(batch_length, n_mels), dropout = dropout, recurrent_dropout = dropout_r))\n",
    "model.add(Dense(NUM_CLASSES_OVERRIDE,activation='softmax'))  #softmax\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])  # sparse_categorical_crossentropy\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(training_data, training_classes, epochs=3, batch_size=batch_size)\n",
    "scores = model.evaluate(testing_data, testing_classes)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "total_end = time.time()\n",
    "print(\"Total Time elapsed: \" + str((total_end-total_time)/60.0) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"LSTMModel.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:thesisCode]",
   "language": "python",
   "name": "conda-env-thesisCode-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
